# -*- coding: utf-8 -*-
"""task1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BT0loEuY8l6clBOUXDeVqm3YF1hV_C6t

# **Import Libraries and load data set**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset from device
data = pd.read_csv('/content/student_data.csv')

"""## **Preprocessing**"""

#convert the values 'Yes' and 'No' in the "Extracurricular Activities" column to 1 and 0.
data['Extracurricular Activities'] = data['Extracurricular Activities'].map({'Yes': 1, 'No': 0})

#Handling missing data
missing_data = data.isnull().sum()
print(missing_data)

# Data central tendency
data.describe()

#Calculate correlation matrix to find out dependent and independent variables
correlation_matrix = data.corr()
plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True)
plt.title('Correlation Matrix')
plt.show()

#creating a scatter plot between different attributes and performance
#Hours Studied Vs Performance
plt.scatter(data["Hours Studied"], data["Performance"])
plt.title("Hours Studied vs Performance")
plt.xlabel("Hours Studied")
plt.ylabel("Performance")
plt.show()

#Previous Scores Vs Performance
plt.scatter(data["Previous Scores"], data["Performance"])
plt.title("Previous Scores vs Performance")
plt.xlabel("Previous Scores")
plt.ylabel("Performance")
plt.show()

#Creating histogram No of students Vs attributes
#Bar plot for Study hours Vs No. of students
plt.hist(data['Hours Studied'], bins=18, edgecolor='black')
plt.title("Distribution of Hours Studied")
plt.xlabel("Hours Studied")
plt.ylabel("No of Students")
plt.show()

#Bar plot for Previous scores and No. of students
plt.hist(data['Previous Scores'], bins=60, edgecolor='black')
plt.title("Distribution of Previous Scores")
plt.xlabel("Previous Scores")
plt.ylabel("No of Students")
plt.show()

#Bar ploat for No. of students and Extracurricular activity
plt.hist(data['Extracurricular Activities'], bins=10, edgecolor='black')
plt.title("Distribution of Extracurricular Activities")
plt.xlabel("Extracurricular Activities")
plt.ylabel("No of Students")
plt.show()

#Bar ploat for sleep duration and No of students
plt.hist(data['Duration of Sleep'], bins=12, edgecolor='black')
plt.title("Distribution of Duration of Sleep")
plt.xlabel("Duration of Sleep")
plt.ylabel("No of Students")
plt.show()

#Bar plot for Sample paper practiced and No of students
plt.hist(data["Sample Question Papers Practiced"], bins=18, edgecolor='black')
plt.title("Distribution of Sample Question Papers Practiced")
plt.xlabel("Sample Question Papers Practiced")
plt.ylabel("No of Students")
plt.show()

#Bar plot of prfotrmance and No of students
plt.hist(data["Performance"], bins=91, edgecolor='black')
plt.title("Distribution of Performance")
plt.xlabel("Performance")
plt.ylabel("No of Students")
plt.show()

"""# **Split dataset for training and testing in 80:20 using random shuffling**"""

train_ratio = 0.8
np.random.seed(11)
shuffled_indices = np.random.permutation(len(data))
split_index = int(len(data) * train_ratio)

train_indices = shuffled_indices[:split_index]
test_indices = shuffled_indices[split_index:]

train_data = data.iloc[train_indices]
test_data = data.iloc[test_indices]

# Separate features and target for training and testing sets
X_training = train_data.drop('Performance', axis=1).values
y_training = train_data['Performance'].values

X_testing = test_data.drop('Performance', axis=1).values
y_testing = test_data['Performance'].values

# Convert data to numpy arrays
X_train_np = np.array(X_training)
X_test_np = np.array(X_testing)
y_train_np = np.array(y_training)
y_test_np = np.array(y_testing)

"""# **Linear Regression**"""

# Add bias term to the feature matrix
X_train_bias = np.c_[np.ones(X_train_np.shape[0]), X_train_np]
X_test_bias = np.c_[np.ones(X_test_np.shape[0]), X_test_np]

# Hyperparameters for Gradient Descent
learning_rate = 0.00035
num_epochs = 170000
mses = []
epochs = []

# Initialize coefficients with zeros
coefficients = np.zeros(X_train_bias.shape[1])

# Gradient Descent
for epoch in range(num_epochs):
    y_pred = np.dot(X_train_bias, coefficients)
    error = y_pred - y_train_np

    gradient = (X_train_bias.T @ error) / len(y_train_np)
    coefficients -= learning_rate * gradient

    mse_epoch = np.mean(error ** 2)
    mses.append(mse_epoch)
    epochs.append(epoch)

# Make predictions on the test data
y_pred = np.dot(X_test_bias, coefficients)
# Calculate the mean squared error
mse = np.mean((y_pred - y_test_np) ** 2)
print("Mean Squared Error:", mse)

"""# **Plot the loss vs epoch curve**"""

# Create a plot
plt.figure(figsize=(10, 6))  # Adjust the figure size if needed
plt.plot(epochs, mses, color='red', label='Loss')

# Set labels and title
plt.xlabel('Epochs')
plt.ylabel('Mean Squared Error')
plt.title('Mean Squared Error over Epochs')
plt.legend()

# Set y-axis limit
plt.ylim(0, 100)
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **prediction of performance of a student according to given data**"""

#Hours of study, Previous score, Extracurricular Activities(1 for Yes)
#Duration of Sleep, Sample Question Papers Practiced
student_data = [7, 95, 1, 7, 6]

# Add bias term
student_data_with_bias = np.array([1] + student_data)

# Make prediction
predicted_performance = np.dot(student_data_with_bias, coefficients)
print("Predicted Performance:", predicted_performance)

"""# **Evaluate performance based on MSE error and R2 Score.**"""

# Calculate R2 Score
mean_y_testing = np.mean(y_testing)
sst = np.sum((y_testing - mean_y_testing) ** 2)
ssr = np.sum((y_pred - y_testing) ** 2)
r2_score = 1 - (ssr / sst)
print("R2 Score:", r2_score)